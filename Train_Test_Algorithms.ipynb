{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXQq5FpkM3Yo"
   },
   "source": [
    "## Funciones √∫tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFcsdq_2wdgt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "def uploadFiles(path='./'):\n",
    "  \"\"\"\n",
    "  Function to upload files from the local PC to the Colab resources\n",
    "  \"\"\"\n",
    "  \n",
    "  # Build the absolute path to the cwd\n",
    "  path = os.path.abspath(path)\n",
    "\n",
    "  # Upload the files\n",
    "  uploaded = files.upload()\n",
    "\n",
    "  # Save the files\n",
    "  for name, data in uploaded.items():\n",
    "    shutil.move(name, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hl-3Bsr5gbMx"
   },
   "outputs": [],
   "source": [
    "def savePickleFile(data, name, path='./'):\n",
    "  \"\"\"\n",
    "  Function to save the received data\n",
    "  \"\"\"\n",
    "  saveData = open(os.path.join(os.path.abspath(path), name), \"wb\")\n",
    "  pickle.dump(data, saveData)\n",
    "  saveData.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1QSL2ptTo0RJ"
   },
   "outputs": [],
   "source": [
    "def loadPickleFile(path):\n",
    "  \"\"\"\n",
    "  Function that loads the file from the received path \n",
    "  and return it\n",
    "  \"\"\"\n",
    "  pickleFile = open(os.path.abspath(path), \"rb\")\n",
    "  object = pickle.load(pickleFile)\n",
    "  pickleFile.close()\n",
    "\n",
    "  return object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RlbymWa7NHkI"
   },
   "source": [
    "# Cargar los sets de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "y3vMWBtgwez5",
    "outputId": "5e412e31-631b-498a-9a5e-126853a08e33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-362532d4-18bb-4a7b-9525-85d7cc0a98a3\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-362532d4-18bb-4a7b-9525-85d7cc0a98a3\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving negative.txt to negative.txt\n",
      "Saving positive.txt to positive.txt\n"
     ]
    }
   ],
   "source": [
    "# Make the dataset directory\n",
    "!mkdir dataset\n",
    "\n",
    "# Upload dataset files\n",
    "uploadFiles('dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_OF3kmzNPHG"
   },
   "source": [
    "# Entrenar el modelo y guardarlo en pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRtrngaV8D13"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from statistics import mode\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "DLcB-i3be4-D",
    "outputId": "d57a63ea-ad6d-472b-c556-143622397c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Needed instalation\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tEvIERzvXJZJ"
   },
   "outputs": [],
   "source": [
    "# Instace the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Read the positive and negative datasets    \n",
    "tweetsPositive = open(\"dataset/positive.txt\", \"r\").read()\n",
    "tweetsNegative = open(\"dataset/negative.txt\", \"r\").read()\n",
    "\n",
    "# Initialize needed list\n",
    "allWords = []\n",
    "documents = []\n",
    "\n",
    "# Filter the allowed word types\n",
    "# - J: Adject\n",
    "# - R: Adverb\n",
    "# - V Verb\n",
    "allowed_word_types = [\"J\"]\n",
    "\n",
    "# To delete all non alphabetic characters\n",
    "regex = re.compile('[^a-zA-Z ]')\n",
    "\n",
    "# Go through the list of positive tweets...\n",
    "for tweet in tweetsPositive.split('\\n'):\n",
    "    # Leave just words\n",
    "    tweet = regex.sub('', tweet)\n",
    "    \n",
    "    # Append the tuple with the label (tweet, positive)\n",
    "    documents.append( (tweet, \"pos\") )\n",
    "    \n",
    "    # Tokenize by words and get tag of each word\n",
    "    byWords = word_tokenize(tweet)\n",
    "    taggedWords = nltk.pos_tag(byWords)\n",
    "    \n",
    "    # Check word for word to leave just the allowed type of words\n",
    "    adjectFilter = list(filter(lambda word: word[1][0] in [\"J\"], taggedWords))\n",
    "    verbFilter = list(filter(lambda word: word[1][0] in [\"V\"], taggedWords))\n",
    "\n",
    "    # Apply lemmatizer to the words\n",
    "    adjectFilter = list(map(lambda word: lemmatizer.lemmatize(word[0].lower(), pos=\"a\"), adjectFilter))\n",
    "    verbFilter = list(map(lambda word: lemmatizer.lemmatize(word[0].lower(), pos=\"v\"), verbFilter))\n",
    "\n",
    "    # Concatenate the words\n",
    "    allWords += adjectFilter + verbFilter\n",
    "\n",
    "\n",
    "# Go through the list of negative tweets...    \n",
    "for tweet in tweetsNegative.split('\\n'):\n",
    "    # Leave just words\n",
    "    tweet = regex.sub('', tweet)\n",
    "\n",
    "    # Append the tuple with the label (tweet, negative)\n",
    "    documents.append( (tweet, \"neg\") )\n",
    "\n",
    "    # Tokenize by words and get tag of each word\n",
    "    byWords = word_tokenize(tweet)\n",
    "    taggedWords = nltk.pos_tag(byWords)\n",
    "\n",
    "    # Check word for word to leave just the allowed type of words\n",
    "    adjectFilter = list(filter(lambda word: word[1][0] in [\"J\"], taggedWords))\n",
    "    verbFilter = list(filter(lambda word: word[1][0] in [\"V\"], taggedWords))\n",
    "\n",
    "    # Apply lemmatizer to the words\n",
    "    adjectFilter = list(map(lambda word: lemmatizer.lemmatize(word[0].lower(), pos=\"a\"), adjectFilter))\n",
    "    verbFilter = list(map(lambda word: lemmatizer.lemmatize(word[0].lower(), pos=\"a\"), verbFilter))\n",
    "\n",
    "    # Concatenate the words\n",
    "    allWords += adjectFilter + verbFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oIUAg6-S3PRp",
    "outputId": "8b338653-5af2-4eb9-93c2-b6bc522b46f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50697\n"
     ]
    }
   ],
   "source": [
    "# Print the number of collected words\n",
    "print(len(allWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gqlSSBQYgDVK",
    "outputId": "23f1ca0d-b488-4288-ee39-3c1d2cd28830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‚ÄòpickleFiles‚Äô: File exists\n"
     ]
    }
   ],
   "source": [
    "# Make the directory to store the pickle files\n",
    "!mkdir pickleFiles\n",
    "\n",
    "# Save the final dataset with labels\n",
    "savePickleFile(documents, \"documents.pickle\", './pickleFiles')\n",
    "\n",
    "# Get the frequency distribution\n",
    "allWords = nltk.FreqDist(allWords)\n",
    "# Leave just the first 5000 words\n",
    "wordFeatures = list(allWords.keys())[:10000]\n",
    "\n",
    "# Save the word features\n",
    "savePickleFile(wordFeatures, \"wordFeatures5k.pickle\", './pickleFiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8TedIIoYjTbC",
    "outputId": "3316d25a-a03e-4dbe-fde2-8ab6c00d74d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature sets:  14002\n"
     ]
    }
   ],
   "source": [
    "def find_features(document):\n",
    "    \"\"\"\n",
    "    Function to use the words as features and\n",
    "    get a dictionary to know which words from the \n",
    "    frequency distribution list appear on the current\n",
    "    sentence\n",
    "    \"\"\"\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for word in wordFeatures:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Get the feature dictionary by sentence\n",
    "featureSets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "savePickleFile(featureSets, 'featuresets.pickle', path='./pickleFiles')\n",
    "\n",
    "# Shuffle the dataset\n",
    "random.shuffle(featureSets)\n",
    "print(\"Number of feature sets: \", len(featureSets))\n",
    "\n",
    "# Calculate the 80%\n",
    "percentageVal = int(len(featureSets) * 0.80)\n",
    "\n",
    "# Prepare the training and testing datasets\n",
    "training_set = featureSets[:percentageVal]\n",
    "testing_set = featureSets[percentageVal:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "9OrN8as70pIj",
    "outputId": "c9c61a8f-7c1e-4b81-eb2f-89cda939a3b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:  11201\n",
      "Testing Set:  2801\n"
     ]
    }
   ],
   "source": [
    "# Print the size of trainin and testing set\n",
    "print(\"Training Set: \", len(training_set))\n",
    "print(\"Testing Set: \", len(testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "7uGIwNuCkZCh",
    "outputId": "9f4d2237-62bb-4c64-b402-c7bcc7780b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 71.36736879685827\n",
      "MNB_classifier5k.pickle accuracy percent: 70.40342734737594\n",
      "BernoulliNB_classifier5k.pickle accuracy percent: 72.0813995001785\n",
      "LogisticRegression_classifier5k.pickle accuracy percent: 71.83148875401642\n",
      "LinearSVC_classifier5k.pickle accuracy percent: 69.93930739021778\n",
      "SGDC_classifier5k.pickle accuracy percent: 70.581935023206\n"
     ]
    }
   ],
   "source": [
    "def trainModel(classifierAlgo, trainingSet, testingSet, name):\n",
    "    \"\"\"\n",
    "    Function to train the modelo of the passed classifier,\n",
    "    test it against the test dataset and sasve the pickle file\n",
    "    \"\"\"\n",
    "    # Train it\n",
    "    classifier = SklearnClassifier(classifierAlgo)\n",
    "    classifier.train(trainingSet)\n",
    "    # Save it\n",
    "    savePickleFile(classifier, name, './pickleFiles')\n",
    "    # Test it\n",
    "    print(\"{} accuracy percent: {}\".format(name, (nltk.classify.accuracy(classifier, testingSet)) * 100))\n",
    "\n",
    "# Train the NLTK Naive Bayes algorithm and save it\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "savePickleFile(classifier, \"originalnaivebayes5k.pickle\", './pickleFiles')\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set)) * 100)\n",
    "\n",
    "# Train the Multinomial Naive Bayes algorithm and save it\n",
    "trainModel(MultinomialNB(), training_set, testing_set, \"MNB_classifier5k.pickle\")\n",
    "\n",
    "# Train the Bernoulli Naive Bayes algorithm and save it\n",
    "trainModel(BernoulliNB(), training_set, testing_set, \"BernoulliNB_classifier5k.pickle\")\n",
    "\n",
    "# Train the Logistic Regression algorithm and save it\n",
    "trainModel(LogisticRegression(), training_set, testing_set, \"LogisticRegression_classifier5k.pickle\")\n",
    "\n",
    "# Train the Linear SVC algorithm and save it\n",
    "trainModel(LinearSVC(), training_set, testing_set, \"LinearSVC_classifier5k.pickle\")\n",
    "\n",
    "# Train the Stochastich Gradiant Descetn algorithm and save it\n",
    "trainModel(SGDClassifier(), training_set, testing_set, \"SGDC_classifier5k.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "0fxlNjYz_MZl",
    "outputId": "829b1e7a-6436-41a0-84aa-998da549be11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: pickleFiles/ (stored 0%)\n",
      "  adding: pickleFiles/featuresets.pickle (deflated 73%)\n",
      "  adding: pickleFiles/LinearSVC_classifier5k.pickle (deflated 48%)\n",
      "  adding: pickleFiles/wordFeatures5k.pickle (deflated 56%)\n",
      "  adding: pickleFiles/documents.pickle (deflated 55%)\n",
      "  adding: pickleFiles/originalnaivebayes5k.pickle (deflated 78%)\n",
      "  adding: pickleFiles/LogisticRegression_classifier5k.pickle (deflated 45%)\n",
      "  adding: pickleFiles/SGDC_classifier5k.pickle (deflated 57%)\n",
      "  adding: pickleFiles/BernoulliNB_classifier5k.pickle (deflated 74%)\n",
      "  adding: pickleFiles/MNB_classifier5k.pickle (deflated 74%)\n"
     ]
    }
   ],
   "source": [
    "# Zip to download the files\n",
    "!zip -r pickleFiles.zip pickleFiles/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sIqtUAAUNYqQ"
   },
   "source": [
    "# Detecci√≥n de sentimiento de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XpOm0E3Q1IwD"
   },
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        \"\"\" \n",
    "        Constructor method that saves the received list \n",
    "        of classifier algorithms\n",
    "        \"\"\"\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        \"\"\"\n",
    "        Method in charge of classifying with all the algorithms,\n",
    "        saving their ouput and getting the mode as if it were a vote.\n",
    "        \"\"\"\n",
    "        votesList = []\n",
    "        for classifie in self._classifiers:\n",
    "            v = classifie.classify(features)\n",
    "            votesList.append(v)\n",
    "        return mode(votesList)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        \"\"\"\n",
    "        Returns the result of dividing the amount of algorithms that\n",
    "        return the mode value divided by the total number of classifiers.\n",
    "        \"\"\"\n",
    "        votesList = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votesList.append(v)\n",
    "\n",
    "        choiceVotes = votesList.count(mode(votesList))\n",
    "        confValue = choiceVotes / len(votesList)\n",
    "        return confValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "NoI0mukb9WyG",
    "outputId": "7af61c86-edc3-4199-9378-de5dae9fc0bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature sets:  14002\n",
      "Voted Classifier Algorithm Accuracy Percent: 81.83408295852074\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import random\n",
    "from statistics import mode\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "def find_features(document):\n",
    "    \"\"\"\n",
    "    Function to use the words as features and\n",
    "    get a dictionary to know which words from the \n",
    "    frequency distribution list appear on the current\n",
    "    sentence\n",
    "    \"\"\"\n",
    "    # Token and tag the sentence\n",
    "    byWords = word_tokenize(document)\n",
    "    taggedWords = nltk.pos_tag(byWords)\n",
    "    \n",
    "    # Check word for word to leave just the allowed type of words\n",
    "    adjectFilter = list(filter(lambda word: word[1][0] in [\"J\"], taggedWords))\n",
    "    verbFilter = list(filter(lambda word: word[1][0] in [\"V\"], taggedWords))\n",
    "\n",
    "    # Apply lemmatizer to the words\n",
    "    adjectFilter = list(map(lambda word: lemmatizer.lemmatize(word[0].lower(), pos=\"a\"), adjectFilter))\n",
    "    verbFilter = list(map(lambda word: lemmatizer.lemmatize(word[0].lower(), pos=\"v\"), verbFilter))\n",
    "\n",
    "    \n",
    "    # Get the features dictionary\n",
    "    features = {}\n",
    "    for word in (adjectFilter + verbFilter):\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Load the features sets\n",
    "featuresSets = loadPickleFile(\"./pickleFiles/featuresets.pickle\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "random.shuffle(featuresSets)\n",
    "print(\"Number of feature sets: \", len(featuresSets))\n",
    "\n",
    "# Prepare the training and testing datasets\n",
    "trainingSet = featuresSets[:10000]\n",
    "testingSet = featuresSets[10000:]\n",
    "\n",
    "# Load the original naive bayes\n",
    "classifier = loadPickleFile(\"./pickleFiles/originalnaivebayes5k.pickle\")\n",
    "\n",
    "# Load the multinomial naive bayes\n",
    "MNB_classifier = loadPickleFile(\"./pickleFiles/MNB_classifier5k.pickle\")\n",
    "\n",
    "# Load the bernoulli naive bayes\n",
    "BernoulliNB_classifier = loadPickleFile(\"./pickleFiles/BernoulliNB_classifier5k.pickle\")\n",
    "\n",
    "# Load the bernoulli naive bayes\n",
    "LogisticRegression_classifier = loadPickleFile(\"./pickleFiles/LogisticRegression_classifier5k.pickle\")\n",
    "\n",
    "# Load the linear svc\n",
    "LinearSVC_classifier = loadPickleFile(\"./pickleFiles/LinearSVC_classifier5k.pickle\")\n",
    "\n",
    "# Load the linear svc\n",
    "SGDC_classifier = loadPickleFile(\"./pickleFiles/SGDC_classifier5k.pickle\")\n",
    "\n",
    "# Build the Vote Classifier\n",
    "votedClassifier = VoteClassifier(classifier, MNB_classifier, BernoulliNB_classifier,\n",
    "                                LogisticRegression_classifier, LinearSVC_classifier)\n",
    "\n",
    "print(\"Voted Classifier Algorithm Accuracy Percent:\", (nltk.classify.accuracy(votedClassifier, testingSet)) * 100)\n",
    "\n",
    "def sentiment(text):\n",
    "  \"\"\"\n",
    "  Function to classify the received text with the voted classifier and returns\n",
    "  the label and confidence of the classification\n",
    "  \"\"\"\n",
    "  textFeatures = find_features(text)\n",
    "  return votedClassifier.classify(textFeatures), votedClassifier.confidence(textFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "2aoqiZmI9Yk3",
    "outputId": "8f4e286e-acdb-4be4-fc92-cee308ca1d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 1.0)\n",
      "('neg', 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Experiment with the vote classifier\n",
    "print(sentiment(\"Very happy with my new blog design - nice to see recent post and popular posts listed together, and it looks great! \"))\n",
    "print(sentiment(\"Sad, sad, sad. I don't know why but I hate this feeling  I wanna sleep and I still can't!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Ugl7NdCB8JY"
   },
   "source": [
    "## Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "P41kVTKBB-Gg",
    "outputId": "de2d4368-c985-4cd8-dc13-e07734d796bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Giraffaloops: welcome 2 sad world https://t.co/oXJpLtdQCZ neg 0.8\n",
      "RT @Fola_ldn: I pray Boga is able to find peace üíîüíîüò™ this is sooo sad https://t.co/n8mWc4i1Or neg 1.0\n",
      "RT @venicitys: quarantine is just making me more sad tbh neg 1.0\n",
      "@KTRTRS @Eatala_Rajender Very sad neg 1.0\n",
      "I got so many closure wigs but I never really feel like my hair done unless I got a frontal wig onüò≠ thats so sad neg 1.0\n",
      "@2EzBeno $hit Sad pos 1.0\n",
      "i hate to say this but it might be üò≠ neg 1.0\n",
      "RT @davidplouffe: Sad but true. pos 1.0\n",
      "RT @HeartAfire777: How ANYONE can‚Äôt see that this colossal blunder of a #PresidentialCandidate is not being used &amp; abused by the @DNC, his‚Ä¶ neg 0.8\n",
      "RT @BourtneySmith: Do you nap when you‚Äôre sad so your mind doesn‚Äôt have to be conscious or are you normal? neg 1.0\n",
      "RT @AngrierWHStaff: Hey guys, the Trump hot mic video is almost certainly fake. \n",
      "\n",
      "I wouldn‚Äôt amplify. \n",
      "\n",
      "And yes, it‚Äôs really sad that just‚Ä¶ neg 1.0\n",
      "please i‚Äôm bawling rn why is this so sad to me??? i just want to give tokoyami a hug oh my god neg 1.0\n",
      "RT @KevKombi: This hasn‚Äôt had enough coverage and it‚Äôs so sad https://t.co/dvtsgwOJFz neg 1.0\n",
      "RT @BrazilBeat1: Sad news from one of the greatest bands ever. pos 0.6\n",
      "RT @h0agh: @tedlieu @realDonaldTrump I could make a snarky comment about Darwin sorting it out in the end Ted, but tbh, it's just incredibl‚Ä¶ neg 1.0\n",
      "@ldramjet @CNBC @SH3L0B Sad boi days pos 0.8\n",
      "hullo, skl if ever na sad kayo or  inaatake ng axienty read this book‚òÅ https://t.co/uWNEbtbR5i neg 1.0\n",
      "It‚Äôs kinda sad I‚Äôve had this account for almost 2 months and I don‚Äôt even have 10 followers. Like wtf üòÇ neg 1.0\n",
      "RT @tuaadgaf: When I'm sad, I draw the mess in my head out on paper. (I ain't that good so don't come for me). But I drew this piece when I‚Ä¶ neg 1.0\n",
      "RT @lenamoonxo: No makeup except a little eyeliner. Dress inside out. Didnt combe hair or shower. Im sad. https://t.co/TOFEUGBERF neg 1.0\n",
      "Sad my sister is leaving me soon. Back to being all by my lonesome ‚òπÔ∏è neg 1.0\n",
      "imagine watching the dance break live and hyping them up the way their backup dancers do :( im so sad all i wanna d‚Ä¶ https://t.co/q7xNnECZBz neg 1.0\n",
      "RT @bkuhoe_: When I think of UshiOi, I always remember the lines ‚ÄúPinagtagpo pero hindi tinadhana.‚Äù\n",
      "\n",
      "Ushijima just locking himself up in hi‚Ä¶ pos 1.0\n",
      "Why Seth Rogen‚Äôs Anti-Israel Rant Matters https://t.co/GIs3JgRHej It's sad that a whole generation of young Jews ha‚Ä¶ https://t.co/9voqEnSDcL neg 1.0\n",
      "RT @SaraCarterDC: #Watch Biden Tells Reporters, He Doesn't Know Where He Is - \n",
      "Sara A. Carter \n",
      "\n",
      "It‚Äôs getting so sad and he‚Äôs the Democratic‚Ä¶ neg 1.0\n",
      "RT @cark_irl: bla bla bla im sad or some shit idk neg 1.0\n",
      "RT @fratboyjaehyun: if you were sad, disappointed, or overwhelmed yesterday, your feelings are still valid. even if it was a mistake, the e‚Ä¶ neg 1.0\n",
      "RT @mygtrivias: Happy Friendship Day ! Remember we alllllll are friends here ~ If you ever feel sad, need someone to lean on, a hand to hol‚Ä¶ neg 1.0\n",
      "i feel sad, again neg 1.0\n",
      "RT @oikawaluvbot: oikawa is one of the most complex characters in hq and seeing him being reduced and mid characterized to a ‚Äúpetty bitch‚Äù‚Ä¶ neg 1.0\n",
      "RT @Fola_ldn: I pray Boga is able to find peace üíîüíîüò™ this is sooo sad https://t.co/n8mWc4i1Or neg 1.0\n",
      "i was literally sitting at my desk in my dorm on twitter it‚Äôs like i knew it was coming neg 1.0\n",
      "edith just made me sad neg 1.0\n",
      "Why is the XX playing over and over and over again I‚Äôm really not trying to be sad today neg 1.0\n",
      "@DrIshMajor @TheRealTahiry @MBC_WEtv @WEtv Wow. Sad. I can only imagine behind closed doors. neg 1.0\n",
      "@elianherrera28 Literally was on that zoom call and as sad as it is no complaint or petition is going to stop the WLC from going up. neg 1.0\n",
      "RT @Giraffaloops: welcome 2 sad world https://t.co/oXJpLtdQCZ neg 0.8\n",
      "Just like an airplane in sad way neg 1.0\n",
      "@BabyGaga94 I‚Äôm not even sure. Just sad af neg 1.0\n",
      "RT @sugasrm: smeraldo be like\n",
      "a) sad \n",
      "b) sad but it‚Äôs b neg 1.0\n",
      "When I don‚Äôt know how to feel or when I‚Äôm mad or sad or whatever, I just write it all down and it‚Äôs definitely therapy for me neg 1.0\n",
      "RT @smalltownandrew: Disgusting! ‚ÄúF**k You Cracker‚Äù BLM Thug Harasses and Threatens White School Kids on Their Trip to DC With Volatile Pro‚Ä¶ pos 1.0\n",
      "RT @NicklesPlanet: This is so sad... where are the people screaming in the streets for these peoples rights and freedoms? This is just awfu‚Ä¶ neg 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8c8cab898310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Start to listen the tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mtwitterStream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtwitterStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, follow, track, async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delimited'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'stream.twitter.com'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, async)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[0;34m(self, resp)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# keep-alive new lines are expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mread_line\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Read the next chunk size from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "# Consumer Key, Consumer Secret Ket\n",
    "consumerKey = \"\"\n",
    "consumerSecret = \"\"\n",
    "# Access token, Access secret token.\n",
    "accessToken = \"\"\n",
    "accessSecret = \"\"\n",
    "\n",
    "class listener(StreamListener):\n",
    "  \"\"\"\n",
    "  Class to listen tweets\n",
    "  \"\"\"\n",
    "\n",
    "  def on_data(self, data):\n",
    "    \"\"\"\n",
    "    Function that defines what to do when \n",
    "    a tweet is listened\n",
    "    \"\"\"\n",
    "\n",
    "    # Store the tweet data\n",
    "    allData = json.loads(data)\n",
    "    \n",
    "    # Store the text from the tweet\n",
    "    textTweet = allData[\"text\"]\n",
    "    \n",
    "    # Get the sentiment and the confidence\n",
    "    sentimentValue, confidenceValue = sentiment(textTweet)\n",
    "    print(textTweet, sentimentValue, confidenceValue)\n",
    "\n",
    "    # If the confidence of the classification is higher than \n",
    "    # 80% write the tweet text on the output file\n",
    "    if (confidenceValue * 100) >= 80:\n",
    "      outputFile = open(\"twitter-sentiment.txt\",\"a\")\n",
    "      finalSentiment = sentimentValue + ' ' + str(confidenceValue)\n",
    "      outputFile.write(finalSentiment)\n",
    "      outputFile.write('\\n')\n",
    "      outputFile.write(textTweet)\n",
    "      outputFile.write('\\n')\n",
    "      outputFile.write('\\n')\n",
    "      outputFile.close()\n",
    "\n",
    "    return True\n",
    "\n",
    "  def on_error(self, status):\n",
    "    \"\"\"\n",
    "    Funtion that defines what to do when there is an error while\n",
    "    listening tweets\n",
    "    \"\"\"\n",
    "    print(status)\n",
    "\n",
    "# Authenticate the app on twitter\n",
    "auth = OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken ,  accessSecret)\n",
    "\n",
    "# Start to listen the tweets\n",
    "twitterStream = Stream(auth, listener())\n",
    "twitterStream.filter(track=['sad'], languages=['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "qeJq0MmNEm07",
    "outputId": "44fce8d9-11fa-4e7b-bd0a-63db7f824d52"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from matplotlib import style\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "# Figure to plot\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "def animate(i):\n",
    "  \"\"\"\n",
    "  Function to animate the sentiment graph\n",
    "  \"\"\"\n",
    "  # Get the data from the output file\n",
    "  pullData = open(\"twitter-sentiment.txt\",\"r\").read()\n",
    "  lines = pullData.split('\\n')\n",
    "\n",
    "\n",
    "  xar = []\n",
    "  yar = []\n",
    "  x = 0\n",
    "  y = 0\n",
    "\n",
    "  for l in lines[-200:]:\n",
    "      x += 1\n",
    "      if \"pos\" in l:\n",
    "          y += 0.7\n",
    "      elif \"neg\" in l:\n",
    "          y -= 0.5\n",
    "\n",
    "      xar.append(x)\n",
    "      yar.append(y)\n",
    "      \n",
    "  ax1.clear()\n",
    "  ax1.plot(xar,yar)\n",
    "ani = animation.FuncAnimation(fig, animate, interval=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjMWdstY-Nim"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of twitter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXQq5FpkM3Yo"
   },
   "source": [
    "## Funciones Ãºtiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFcsdq_2wdgt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "def uploadFiles(path='./'):\n",
    "  \"\"\"\n",
    "  Function to upload files from the local PC to the Colab resources\n",
    "  \"\"\"\n",
    "  \n",
    "  # Build the absolute path to the cwd\n",
    "  path = os.path.abspath(path)\n",
    "\n",
    "  # Upload the files\n",
    "  uploaded = files.upload()\n",
    "\n",
    "  # Save the files\n",
    "  for name, data in uploaded.items():\n",
    "    shutil.move(name, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hl-3Bsr5gbMx"
   },
   "outputs": [],
   "source": [
    "def savePickleFile(data, name, path='./'):\n",
    "  \"\"\"\n",
    "  Function to save the received data\n",
    "  \"\"\"\n",
    "  saveData = open(os.path.join(os.path.abspath(path), name), \"wb\")\n",
    "  pickle.dump(data, saveData)\n",
    "  saveData.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1QSL2ptTo0RJ"
   },
   "outputs": [],
   "source": [
    "def loadPickleFile(path):\n",
    "  \"\"\"\n",
    "  Function that loads the file from the received path \n",
    "  and return it\n",
    "  \"\"\"\n",
    "  pickleFile = open(os.path.abspath(path), \"rb\")\n",
    "  object = pickle.load(pickleFile)\n",
    "  pickleFile.close()\n",
    "\n",
    "  return object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RlbymWa7NHkI"
   },
   "source": [
    "# Cargar los sets de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "y3vMWBtgwez5",
    "outputId": "5e412e31-631b-498a-9a5e-126853a08e33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-362532d4-18bb-4a7b-9525-85d7cc0a98a3\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-362532d4-18bb-4a7b-9525-85d7cc0a98a3\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving negative.txt to negative.txt\n",
      "Saving positive.txt to positive.txt\n"
     ]
    }
   ],
   "source": [
    "# Make the dataset directory\n",
    "!mkdir dataset\n",
    "\n",
    "# Upload dataset files\n",
    "uploadFiles('dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_OF3kmzNPHG"
   },
   "source": [
    "# Entrenar el modelo y guardarlo en pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRtrngaV8D13"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from statistics import mode\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "DLcB-i3be4-D",
    "outputId": "d57a63ea-ad6d-472b-c556-143622397c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Needed instalation\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tEvIERzvXJZJ"
   },
   "outputs": [],
   "source": [
    "# Instace the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Read the positive and negative datasets    \n",
    "tweetsPositive = open(\"dataset/positive.txt\", \"r\").read()\n",
    "tweetsNegative = open(\"dataset/negative.txt\", \"r\").read()\n",
    "\n",
    "# Initialize needed list\n",
    "allWords = []\n",
    "documents = []\n",
    "\n",
    "# Filter the allowed word types\n",
    "# - J: Adject\n",
    "# - R: Adverb\n",
    "# - V Verb\n",
    "allowed_word_types = [\"J\"]\n",
    "\n",
    "# To delete all non alphabetic characters\n",
    "regex = re.compile('[^a-zA-Z ]')\n",
    "\n",
    "# Go through the list of positive tweets...\n",
    "for tweet in tweetsPositive.split('\\n'):\n",
    "    # Leave just words\n",
    "    tweet = regex.sub('', tweet)\n",
    "    \n",
    "    # Append the tuple with the label (tweet, positive)\n",
    "    documents.append( (tweet, \"pos\") )\n",
    "    \n",
    "    # Tokenize by words and get tag of each word\n",
    "    byWords = word_tokenize(tweet)\n",
    "    taggedWords = nltk.pos_tag(byWords)\n",
    "    \n",
    "    # Check word for word to leave just the allowed type of words\n",
    "    adjectFilter = list(filter(lambda word: word[1][0] in [\"J\"], taggedWords))\n",
    "    verbFilter = list(filter(lambda word: word[1][0] in [\"V\"], taggedWords))\n",
    "\n",
    "    # Apply lemmatizer to the words\n",
    "    adjectFilter = list(map(lambda word: lemmatizer.lemmatize(word[0].lower(), pos=\"a\"), adjectFilter))\n",
    "    verbFilter = list(map(lambda word: lemmatizer.lemmatize(word[0].lower(), pos=\"v\"), verbFilter))\n",
    "\n",
    "    # Concatenate the words\n",
    "    allWords += adjectFilter + verbFilter\n",
    "\n",
    "\n",
    "# Go through the list of negative tweets...    \n",
    "for tweet in tweetsNegative.split('\\n'):\n",
    "    # Leave just words\n",
    "    tweet = regex.sub('', tweet)\n",
    "\n",
    "    # Append the tuple with the label (tweet, negative)\n",
    "    documents.append( (tweet, \"neg\") )\n",
    "\n",
    "    # Tokenize by words and get tag of each word\n",
    "    byWords = word_tokenize(tweet)\n",
    "    taggedWords = nltk.pos_tag(byWords)\n",
    "\n",
    "    # Check word for word to leave just the allowed type of words\n",
    "    adjectFilter = list(filter(lambda word: word[1][0] in [\"J\"], taggedWords))\n",
    "    verbFilter = list(filter(lambda word: word[1][0] in [\"V\"], taggedWords))\n",
    "\n",
    "    # Apply lemmatizer to the words\n",
    "    adjectFilter = list(map(lambda word: lemmatizer.lemmatize(word[0].lower(), pos=\"a\"), adjectFilter))\n",
    "    verbFilter = list(map(lambda word: lemmatizer.lemmatize(word[0].lower(), pos=\"a\"), verbFilter))\n",
    "\n",
    "    # Concatenate the words\n",
    "    allWords += adjectFilter + verbFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oIUAg6-S3PRp",
    "outputId": "8b338653-5af2-4eb9-93c2-b6bc522b46f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50697\n"
     ]
    }
   ],
   "source": [
    "# Print the number of collected words\n",
    "print(len(allWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gqlSSBQYgDVK",
    "outputId": "23f1ca0d-b488-4288-ee39-3c1d2cd28830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory âpickleFilesâ: File exists\n"
     ]
    }
   ],
   "source": [
    "# Make the directory to store the pickle files\n",
    "!mkdir pickleFiles\n",
    "\n",
    "# Save the final dataset with labels\n",
    "savePickleFile(documents, \"documents.pickle\", './pickleFiles')\n",
    "\n",
    "# Get the frequency distribution\n",
    "allWords = nltk.FreqDist(allWords)\n",
    "# Leave just the first 5000 words\n",
    "wordFeatures = list(allWords.keys())[:10000]\n",
    "\n",
    "# Save the word features\n",
    "savePickleFile(wordFeatures, \"wordFeatures5k.pickle\", './pickleFiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8TedIIoYjTbC",
    "outputId": "3316d25a-a03e-4dbe-fde2-8ab6c00d74d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature sets:  14002\n"
     ]
    }
   ],
   "source": [
    "def find_features(document):\n",
    "    \"\"\"\n",
    "    Function to use the words as features and\n",
    "    get a dictionary to know which words from the \n",
    "    frequency distribution list appear on the current\n",
    "    sentence\n",
    "    \"\"\"\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for word in wordFeatures:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Get the feature dictionary by sentence\n",
    "featureSets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "savePickleFile(featureSets, 'featuresets.pickle', path='./pickleFiles')\n",
    "\n",
    "# Shuffle the dataset\n",
    "random.shuffle(featureSets)\n",
    "print(\"Number of feature sets: \", len(featureSets))\n",
    "\n",
    "# Calculate the 80%\n",
    "percentageVal = int(len(featureSets) * 0.80)\n",
    "\n",
    "# Prepare the training and testing datasets\n",
    "training_set = featureSets[:percentageVal]\n",
    "testing_set = featureSets[percentageVal:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "9OrN8as70pIj",
    "outputId": "c9c61a8f-7c1e-4b81-eb2f-89cda939a3b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:  11201\n",
      "Testing Set:  2801\n"
     ]
    }
   ],
   "source": [
    "# Print the size of trainin and testing set\n",
    "print(\"Training Set: \", len(training_set))\n",
    "print(\"Testing Set: \", len(testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "7uGIwNuCkZCh",
    "outputId": "9f4d2237-62bb-4c64-b402-c7bcc7780b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 71.36736879685827\n",
      "MNB_classifier5k.pickle accuracy percent: 70.40342734737594\n",
      "BernoulliNB_classifier5k.pickle accuracy percent: 72.0813995001785\n",
      "LogisticRegression_classifier5k.pickle accuracy percent: 71.83148875401642\n",
      "LinearSVC_classifier5k.pickle accuracy percent: 69.93930739021778\n",
      "SGDC_classifier5k.pickle accuracy percent: 70.581935023206\n"
     ]
    }
   ],
   "source": [
    "def trainModel(classifierAlgo, trainingSet, testingSet, name):\n",
    "    \"\"\"\n",
    "    Function to train the modelo of the passed classifier,\n",
    "    test it against the test dataset and sasve the pickle file\n",
    "    \"\"\"\n",
    "    # Train it\n",
    "    classifier = SklearnClassifier(classifierAlgo)\n",
    "    classifier.train(trainingSet)\n",
    "    # Save it\n",
    "    savePickleFile(classifier, name, './pickleFiles')\n",
    "    # Test it\n",
    "    print(\"{} accuracy percent: {}\".format(name, (nltk.classify.accuracy(classifier, testingSet)) * 100))\n",
    "\n",
    "# Train the NLTK Naive Bayes algorithm and save it\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "savePickleFile(classifier, \"originalnaivebayes5k.pickle\", './pickleFiles')\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set)) * 100)\n",
    "\n",
    "# Train the Multinomial Naive Bayes algorithm and save it\n",
    "trainModel(MultinomialNB(), training_set, testing_set, \"MNB_classifier5k.pickle\")\n",
    "\n",
    "# Train the Bernoulli Naive Bayes algorithm and save it\n",
    "trainModel(BernoulliNB(), training_set, testing_set, \"BernoulliNB_classifier5k.pickle\")\n",
    "\n",
    "# Train the Logistic Regression algorithm and save it\n",
    "trainModel(LogisticRegression(), training_set, testing_set, \"LogisticRegression_classifier5k.pickle\")\n",
    "\n",
    "# Train the Linear SVC algorithm and save it\n",
    "trainModel(LinearSVC(), training_set, testing_set, \"LinearSVC_classifier5k.pickle\")\n",
    "\n",
    "# Train the Stochastich Gradiant Descetn algorithm and save it\n",
    "trainModel(SGDClassifier(), training_set, testing_set, \"SGDC_classifier5k.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "0fxlNjYz_MZl",
    "outputId": "829b1e7a-6436-41a0-84aa-998da549be11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: pickleFiles/ (stored 0%)\n",
      "  adding: pickleFiles/featuresets.pickle (deflated 73%)\n",
      "  adding: pickleFiles/LinearSVC_classifier5k.pickle (deflated 48%)\n",
      "  adding: pickleFiles/wordFeatures5k.pickle (deflated 56%)\n",
      "  adding: pickleFiles/documents.pickle (deflated 55%)\n",
      "  adding: pickleFiles/originalnaivebayes5k.pickle (deflated 78%)\n",
      "  adding: pickleFiles/LogisticRegression_classifier5k.pickle (deflated 45%)\n",
      "  adding: pickleFiles/SGDC_classifier5k.pickle (deflated 57%)\n",
      "  adding: pickleFiles/BernoulliNB_classifier5k.pickle (deflated 74%)\n",
      "  adding: pickleFiles/MNB_classifier5k.pickle (deflated 74%)\n"
     ]
    }
   ],
   "source": [
    "# Zip to download the files\n",
    "!zip -r pickleFiles.zip pickleFiles/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sIqtUAAUNYqQ"
   },
   "source": [
    "# DetecciÃ³n de sentimiento de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XpOm0E3Q1IwD"
   },
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        \"\"\" \n",
    "        Constructor method that saves the received list \n",
    "        of classifier algorithms\n",
    "        \"\"\"\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        \"\"\"\n",
    "        Method in charge of classifying with all the algorithms,\n",
    "        saving their ouput and getting the mode as if it were a vote.\n",
    "        \"\"\"\n",
    "        votesList = []\n",
    "        for classifie in self._classifiers:\n",
    "            v = classifie.classify(features)\n",
    "            votesList.append(v)\n",
    "        return mode(votesList)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        \"\"\"\n",
    "        Returns the result of dividing the amount of algorithms that\n",
    "        return the mode value divided by the total number of classifiers.\n",
    "        \"\"\"\n",
    "        votesList = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votesList.append(v)\n",
    "\n",
    "        choiceVotes = votesList.count(mode(votesList))\n",
    "        confValue = choiceVotes / len(votesList)\n",
    "        return confValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "NoI0mukb9WyG",
    "outputId": "7af61c86-edc3-4199-9378-de5dae9fc0bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature sets:  14002\n",
      "Voted Classifier Algorithm Accuracy Percent: 81.83408295852074\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import random\n",
    "from statistics import mode\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "def find_features(document):\n",
    "    \"\"\"\n",
    "    Function to use the words as features and\n",
    "    get a dictionary to know which words from the \n",
    "    frequency distribution list appear on the current\n",
    "    sentence\n",
    "    \"\"\"\n",
    "    # Token and tag the sentence\n",
    "    byWords = word_tokenize(document)\n",
    "    taggedWords = nltk.pos_tag(byWords)\n",
    "    \n",
    "    # Check word for word to leave just the allowed type of words\n",
    "    adjectFilter = list(filter(lambda word: word[1][0] in [\"J\"], taggedWords))\n",
    "    verbFilter = list(filter(lambda word: word[1][0] in [\"V\"], taggedWords))\n",
    "\n",
    "    # Apply lemmatizer to the words\n",
    "    adjectFilter = list(map(lambda word: lemmatizer.lemmatize(word[0].lower(), pos=\"a\"), adjectFilter))\n",
    "    verbFilter = list(map(lambda word: lemmatizer.lemmatize(word[0].lower(), pos=\"v\"), verbFilter))\n",
    "\n",
    "    \n",
    "    # Get the features dictionary\n",
    "    features = {}\n",
    "    for word in (adjectFilter + verbFilter):\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Load the features sets\n",
    "featuresSets = loadPickleFile(\"./pickleFiles/featuresets.pickle\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "random.shuffle(featuresSets)\n",
    "print(\"Number of feature sets: \", len(featuresSets))\n",
    "\n",
    "# Prepare the training and testing datasets\n",
    "trainingSet = featuresSets[:10000]\n",
    "testingSet = featuresSets[10000:]\n",
    "\n",
    "# Load the original naive bayes\n",
    "classifier = loadPickleFile(\"./pickleFiles/originalnaivebayes5k.pickle\")\n",
    "\n",
    "# Load the multinomial naive bayes\n",
    "MNB_classifier = loadPickleFile(\"./pickleFiles/MNB_classifier5k.pickle\")\n",
    "\n",
    "# Load the bernoulli naive bayes\n",
    "BernoulliNB_classifier = loadPickleFile(\"./pickleFiles/BernoulliNB_classifier5k.pickle\")\n",
    "\n",
    "# Load the bernoulli naive bayes\n",
    "LogisticRegression_classifier = loadPickleFile(\"./pickleFiles/LogisticRegression_classifier5k.pickle\")\n",
    "\n",
    "# Load the linear svc\n",
    "LinearSVC_classifier = loadPickleFile(\"./pickleFiles/LinearSVC_classifier5k.pickle\")\n",
    "\n",
    "# Load the linear svc\n",
    "SGDC_classifier = loadPickleFile(\"./pickleFiles/SGDC_classifier5k.pickle\")\n",
    "\n",
    "# Build the Vote Classifier\n",
    "votedClassifier = VoteClassifier(classifier, MNB_classifier, BernoulliNB_classifier,\n",
    "                                LogisticRegression_classifier, LinearSVC_classifier)\n",
    "\n",
    "print(\"Voted Classifier Algorithm Accuracy Percent:\", (nltk.classify.accuracy(votedClassifier, testingSet)) * 100)\n",
    "\n",
    "def sentiment(text):\n",
    "  \"\"\"\n",
    "  Function to classify the received text with the voted classifier and returns\n",
    "  the label and confidence of the classification\n",
    "  \"\"\"\n",
    "  textFeatures = find_features(text)\n",
    "  return votedClassifier.classify(textFeatures), votedClassifier.confidence(textFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "2aoqiZmI9Yk3",
    "outputId": "8f4e286e-acdb-4be4-fc92-cee308ca1d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pos', 1.0)\n",
      "('neg', 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Experiment with the vote classifier\n",
    "print(sentiment(\"Very happy with my new blog design - nice to see recent post and popular posts listed together, and it looks great! \"))\n",
    "print(sentiment(\"Sad, sad, sad. I don't know why but I hate this feeling  I wanna sleep and I still can't!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Ugl7NdCB8JY"
   },
   "source": [
    "## Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "P41kVTKBB-Gg",
    "outputId": "de2d4368-c985-4cd8-dc13-e07734d796bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Giraffaloops: welcome 2 sad world https://t.co/oXJpLtdQCZ neg 0.8\n",
      "RT @Fola_ldn: I pray Boga is able to find peace ðððª this is sooo sad https://t.co/n8mWc4i1Or neg 1.0\n",
      "RT @venicitys: quarantine is just making me more sad tbh neg 1.0\n",
      "@KTRTRS @Eatala_Rajender Very sad neg 1.0\n",
      "I got so many closure wigs but I never really feel like my hair done unless I got a frontal wig onð­ thats so sad neg 1.0\n",
      "@2EzBeno $hit Sad pos 1.0\n",
      "i hate to say this but it might be ð­ neg 1.0\n",
      "RT @davidplouffe: Sad but true. pos 1.0\n",
      "RT @HeartAfire777: How ANYONE canât see that this colossal blunder of a #PresidentialCandidate is not being used &amp; abused by the @DNC, hisâ¦ neg 0.8\n",
      "RT @BourtneySmith: Do you nap when youâre sad so your mind doesnât have to be conscious or are you normal? neg 1.0\n",
      "RT @AngrierWHStaff: Hey guys, the Trump hot mic video is almost certainly fake. \n",
      "\n",
      "I wouldnât amplify. \n",
      "\n",
      "And yes, itâs really sad that justâ¦ neg 1.0\n",
      "please iâm bawling rn why is this so sad to me??? i just want to give tokoyami a hug oh my god neg 1.0\n",
      "RT @KevKombi: This hasnât had enough coverage and itâs so sad https://t.co/dvtsgwOJFz neg 1.0\n",
      "RT @BrazilBeat1: Sad news from one of the greatest bands ever. pos 0.6\n",
      "RT @h0agh: @tedlieu @realDonaldTrump I could make a snarky comment about Darwin sorting it out in the end Ted, but tbh, it's just incrediblâ¦ neg 1.0\n",
      "@ldramjet @CNBC @SH3L0B Sad boi days pos 0.8\n",
      "hullo, skl if ever na sad kayo or  inaatake ng axienty read this bookâ https://t.co/uWNEbtbR5i neg 1.0\n",
      "Itâs kinda sad Iâve had this account for almost 2 months and I donât even have 10 followers. Like wtf ð neg 1.0\n",
      "RT @tuaadgaf: When I'm sad, I draw the mess in my head out on paper. (I ain't that good so don't come for me). But I drew this piece when Iâ¦ neg 1.0\n",
      "RT @lenamoonxo: No makeup except a little eyeliner. Dress inside out. Didnt combe hair or shower. Im sad. https://t.co/TOFEUGBERF neg 1.0\n",
      "Sad my sister is leaving me soon. Back to being all by my lonesome â¹ï¸ neg 1.0\n",
      "imagine watching the dance break live and hyping them up the way their backup dancers do :( im so sad all i wanna dâ¦ https://t.co/q7xNnECZBz neg 1.0\n",
      "RT @bkuhoe_: When I think of UshiOi, I always remember the lines âPinagtagpo pero hindi tinadhana.â\n",
      "\n",
      "Ushijima just locking himself up in hiâ¦ pos 1.0\n",
      "Why Seth Rogenâs Anti-Israel Rant Matters https://t.co/GIs3JgRHej It's sad that a whole generation of young Jews haâ¦ https://t.co/9voqEnSDcL neg 1.0\n",
      "RT @SaraCarterDC: #Watch Biden Tells Reporters, He Doesn't Know Where He Is - \n",
      "Sara A. Carter \n",
      "\n",
      "Itâs getting so sad and heâs the Democraticâ¦ neg 1.0\n",
      "RT @cark_irl: bla bla bla im sad or some shit idk neg 1.0\n",
      "RT @fratboyjaehyun: if you were sad, disappointed, or overwhelmed yesterday, your feelings are still valid. even if it was a mistake, the eâ¦ neg 1.0\n",
      "RT @mygtrivias: Happy Friendship Day ! Remember we alllllll are friends here ~ If you ever feel sad, need someone to lean on, a hand to holâ¦ neg 1.0\n",
      "i feel sad, again neg 1.0\n",
      "RT @oikawaluvbot: oikawa is one of the most complex characters in hq and seeing him being reduced and mid characterized to a âpetty bitchââ¦ neg 1.0\n",
      "RT @Fola_ldn: I pray Boga is able to find peace ðððª this is sooo sad https://t.co/n8mWc4i1Or neg 1.0\n",
      "i was literally sitting at my desk in my dorm on twitter itâs like i knew it was coming neg 1.0\n",
      "edith just made me sad neg 1.0\n",
      "Why is the XX playing over and over and over again Iâm really not trying to be sad today neg 1.0\n",
      "@DrIshMajor @TheRealTahiry @MBC_WEtv @WEtv Wow. Sad. I can only imagine behind closed doors. neg 1.0\n",
      "@elianherrera28 Literally was on that zoom call and as sad as it is no complaint or petition is going to stop the WLC from going up. neg 1.0\n",
      "RT @Giraffaloops: welcome 2 sad world https://t.co/oXJpLtdQCZ neg 0.8\n",
      "Just like an airplane in sad way neg 1.0\n",
      "@BabyGaga94 Iâm not even sure. Just sad af neg 1.0\n",
      "RT @sugasrm: smeraldo be like\n",
      "a) sad \n",
      "b) sad but itâs b neg 1.0\n",
      "When I donât know how to feel or when Iâm mad or sad or whatever, I just write it all down and itâs definitely therapy for me neg 1.0\n",
      "RT @smalltownandrew: Disgusting! âF**k You Crackerâ BLM Thug Harasses and Threatens White School Kids on Their Trip to DC With Volatile Proâ¦ pos 1.0\n",
      "RT @NicklesPlanet: This is so sad... where are the people screaming in the streets for these peoples rights and freedoms? This is just awfuâ¦ neg 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8c8cab898310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Start to listen the tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mtwitterStream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtwitterStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, follow, track, async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delimited'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'stream.twitter.com'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, async)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[0;34m(self, resp)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# keep-alive new lines are expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mread_line\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Read the next chunk size from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "# Consumer Key, Consumer Secret Ket\n",
    "consumerKey = \"\"\n",
    "consumerSecret = \"\"\n",
    "# Access token, Access secret token.\n",
    "accessToken = \"\"\n",
    "accessSecret = \"\"\n",
    "\n",
    "class listener(StreamListener):\n",
    "  \"\"\"\n",
    "  Class to listen tweets\n",
    "  \"\"\"\n",
    "\n",
    "  def on_data(self, data):\n",
    "    \"\"\"\n",
    "    Function that defines what to do when \n",
    "    a tweet is listened\n",
    "    \"\"\"\n",
    "\n",
    "    # Store the tweet data\n",
    "    allData = json.loads(data)\n",
    "    \n",
    "    # Store the text from the tweet\n",
    "    textTweet = allData[\"text\"]\n",
    "    \n",
    "    # Get the sentiment and the confidence\n",
    "    sentimentValue, confidenceValue = sentiment(textTweet)\n",
    "    print(textTweet, sentimentValue, confidenceValue)\n",
    "\n",
    "    # If the confidence of the classification is higher than \n",
    "    # 80% write the tweet text on the output file\n",
    "    if (confidenceValue * 100) >= 80:\n",
    "      outputFile = open(\"twitter-sentiment.txt\",\"a\")\n",
    "      finalSentiment = sentimentValue + ' ' + str(confidenceValue)\n",
    "      outputFile.write(finalSentiment)\n",
    "      outputFile.write('\\n')\n",
    "      outputFile.write(textTweet)\n",
    "      outputFile.write('\\n')\n",
    "      outputFile.write('\\n')\n",
    "      outputFile.close()\n",
    "\n",
    "    return True\n",
    "\n",
    "  def on_error(self, status):\n",
    "    \"\"\"\n",
    "    Funtion that defines what to do when there is an error while\n",
    "    listening tweets\n",
    "    \"\"\"\n",
    "    print(status)\n",
    "\n",
    "# Authenticate the app on twitter\n",
    "auth = OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken ,  accessSecret)\n",
    "\n",
    "# Start to listen the tweets\n",
    "twitterStream = Stream(auth, listener())\n",
    "twitterStream.filter(track=['sad'], languages=['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "qeJq0MmNEm07",
    "outputId": "44fce8d9-11fa-4e7b-bd0a-63db7f824d52"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from matplotlib import style\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "# Figure to plot\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "def animate(i):\n",
    "  \"\"\"\n",
    "  Function to animate the sentiment graph\n",
    "  \"\"\"\n",
    "  # Get the data from the output file\n",
    "  pullData = open(\"twitter-sentiment.txt\",\"r\").read()\n",
    "  lines = pullData.split('\\n')\n",
    "\n",
    "\n",
    "  xar = []\n",
    "  yar = []\n",
    "  x = 0\n",
    "  y = 0\n",
    "\n",
    "  for l in lines[-200:]:\n",
    "      x += 1\n",
    "      if \"pos\" in l:\n",
    "          y += 0.7\n",
    "      elif \"neg\" in l:\n",
    "          y -= 0.5\n",
    "\n",
    "      xar.append(x)\n",
    "      yar.append(y)\n",
    "      \n",
    "  ax1.clear()\n",
    "  ax1.plot(xar,yar)\n",
    "ani = animation.FuncAnimation(fig, animate, interval=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjMWdstY-Nim"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of twitter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
